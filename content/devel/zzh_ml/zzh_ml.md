Title: 周志华《机器学习》读书笔记
Date: 2017-04-20
Modified: 2017-04-20
Category: machine learn
Tags: machine learn

# 模型评估与选择
## 经验误差与过拟合

## 评估方法

### 留出法
直接将数据划分为互斥的集合，其中一个作为训练集，一个作为测试集。用训练集训练出模型后，用测试集进行评估。

训练和测试集的划分应尽量保持数据分布的一致，避免因数据划分过程引入额外的偏差而对最终结果产生影响。

一般将数据的2/3~4/5用于训练

### 交叉验证法
将数据集划分为k个大小相似的互斥子集。每个子集都尽可能保持数据分布的一致性。每次用k-1个子集的并集作为训练集，余下的那个子集作为测试集。最终可以得到k组训练/测试集，从而可以进行k次训练和测试，最终返回的是这k个测试结果的均值。通常称为“k拆交叉验证法”。k经常取10。

它的特例为留一法。令k等于整个数据集样本个数m。它的缺点是数据量大时计算量也大。

### 自助法
对包含m个样本的数据集D进行随机采样，每次随机挑选一个样本拷贝到数据集D'，然后将该样本放回D，重复执行m次后，就能得到包含m个样本的数据集D'，它是自助采样的结果。D中会有一部分样本在D'中重复出现，另一部分样本不会出现。约有36.8%的样本不会出现在D'中，可以将D'用作训练，D/D'（集合D减D'）用作测试。这样实际评估的模与期望评估的模型都使用m个训练样本，而仍有约1/3的没在训练集中出现的样本用于测试。这样的测试结果，亦称“包外估计”。

它在数据集小、难于有次划分训练/测试集时很有用。如果初始数据量足够大，留出法和交叉验证法更常用一些。

### 调参与最终模型
模型在实际使用中遇到的数据称为测试数据，为了加以区分，模型评估与选择中用于评估测试的数据集称为“验证集”。用测试集上判别模型在实际使用时的泛化能力，而把训练数据另外划分为训练集和验证集，基于验证集上的性能来进行模型选择和调参。

## 性能度量
衡量模型泛化能力的评价标准就是性能度量。

给定样例集 $D={(x_1,y_1),(x_2,y_2),...,(x_m,y_m)}$ ，其中 $y_i$ 是示例 $x_i$ 的真实标记。要评估学习器 $f$ 的性能，就要把学习器预测结果 $f(x)$ 与真实标记 $y$ 进行比较。

均方误差
$$
E(f;D) = \frac{1}{m}\sum_{i=1}^m (f(x_i) - y_i)^2
$$

### 错误率与精度
分别是分类错误和正确的样本数占样本总数的比例。

错误率
$$
E(f;D) = \frac{1}{m}\sum_{i=1}^m \textrm{II} (f(x_i) \neq y_i)
$$

精度
$$
acc(f;D) = \frac{1}{m}\sum_{i=1}^m \textrm{II} (f(x_i) = y_i)\\
 = 1 - E(f;D)
$$

### 查准率、查全率与F1
混淆矩阵
$$
\begin{array}{c|lc}
& \rlap{\text{测试情况}} \\
真实情况 & \text{正例P} & \text{反例N} \\
\hline
正例T & TP(真正例) & FN(假反例) \\
反例F & FP(假正例) & TN(真反例)
\end{array}
$$

查准率，如：检索出来的信息中有多少比例是用户感兴趣的
$$
P = \frac{TP}{TP + FP}
$$

查全率，如：用户感兴趣的信息中有多少被检索出来
$$
R = \frac{TP}{TP + FN}
$$

查准率和查全率是一对矛盾。以查全率为横轴查准率为纵轴，得到查准率-查全率曲线，简称“P-R曲线”，如果一个曲线“包住”另一个曲线，则外面的曲线代表的学习器的性能优于内部的。如果曲线有交叉则可以通过“平衡点(Break-Event Point，BEP)”来度量，BEP是“查准率=查全率”时的取值。

比BEP有些过于简化，更常用的是F1度量。
$$
F1 = \frac{2 \times P \times R}{P + R} = \frac{2 \times TP}{样例总数 + TP - TN}
$$

F1度量中如果查全率更重要，则可以使用F1度量的一般形式—— $F_\beta$ ，它能让我们表达出对查准率/查全率的不同偏好。
$$
F_\beta = \frac{(1 + \beta^2) \times P \times R}{(\beta^2 \times P) + R}
$$
其中 $\beta \ge 0$ 度量了查全率对查准率的相对重要性。 $\beta = 1$ 时退化为标准的F1； $\beta \gt 1$ 时查全率有更大影响； $\beta \lt 1$ 时查准率有更大影响。

当需要对多个混淆矩阵进行综合考察时，直接的做法是先在各混淆矩阵上分别计算出查准率和查全率记为 $(P_1,R_1),(P_2,R_2),...,(P_n,R_n)$ 再计算平均值，这样得到“宏查准率”、“宏查全率”、“宏F1”：
$$
    macro\-P = \frac{1}{n}\sum_{i=1}^n P_i
$$
